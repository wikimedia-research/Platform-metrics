{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from wmfdata import hive\n",
    "from wmfdata import spark \n",
    "from wmfdata.utils import print_err, pd_display_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSV file where metrics are or will be saved\n",
    "FILENAME = \"metrics/metrics.tsv\"\n",
    "\n",
    "# Metric month. The mediawiki_history snapshot must be from the metrics month or later.\n",
    "last_month = datetime.date.today().replace(day=1) - datetime.timedelta(days=1)\n",
    "\n",
    "METRICS_MONTH_TEXT = last_month.strftime(\"%Y-%m\")\n",
    "MEDIAWIKI_HISTORY_SNAPSHOT = last_month.strftime(\"%Y-%m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our metrics month to all the formats we need and provide them in a dict\n",
    "# so we can easily use them to format strings\n",
    "metrics_month = METRICS_MONTH_TEXT\n",
    "date_params = {\n",
    "    \"mediawiki_history_snapshot\": MEDIAWIKI_HISTORY_SNAPSHOT,\n",
    "    \"metrics_month\": str(metrics_month), \n",
    "    \"metrics_month_first_day\": str((datetime.date.today()- datetime.timedelta(days=31)).replace(day=1)),\n",
    "    \"metrics_month_last_day\": str(last_month),\n",
    "    \"metrics_year\": last_month.year,\n",
    "    \"metrics_cur_month\" : last_month.month\n",
    "}\n",
    "\n",
    "# Load any previous results\n",
    "try:\n",
    "    old_metrics = (\n",
    "        pd.read_csv(FILENAME, sep=\"\\t\", parse_dates = [\"month\"])\n",
    "        .set_index(\"month\")\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    old_metrics = None\n",
    "    \n",
    "def prepare_query(filename):\n",
    "    return (\n",
    "        Path(filename)\n",
    "        .read_text()\n",
    "        .format(**date_params)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running structured_data_used on spark...\n",
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n",
      "Running wikidata_items on spark...\n",
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n",
      "Running wikidata_items_being_reused on spark...\n",
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "queries = {\n",
    "    \"structured_data_used\": {\n",
    "        \"file\": \"queries/structured_data_used.hql\",\n",
    "        \"engine\": \"spark\"\n",
    "    },\n",
    "    \"wikidata_items\": {\n",
    "        \"file\": \"queries/wikidata_items.hql\",\n",
    "        \"engine\": \"spark\"\n",
    "    },\n",
    "    \"wikidata_items_being_reused\": {\n",
    "        \"file\": \"queries/wikidata_items_being_reused.hql\",\n",
    "        \"engine\": \"spark\"\n",
    "    }\n",
    "    \n",
    "       \n",
    "}\n",
    "\n",
    "\n",
    "for key, val in queries.items():\n",
    "    query = prepare_query(val[\"file\"])\n",
    "    engine = val[\"engine\"]\n",
    "    print_err(\"Running {} on {}...\".format(key, engine))\n",
    "    \n",
    "    if engine == \"mariadb\":\n",
    "        result = mariadb.run(query)\n",
    "    elif engine == \"spark\":\n",
    "        result = spark.run(query)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown engine specified.\") \n",
    "    \n",
    "    result = result.assign(month=lambda df: pd.to_datetime(df[\"month\"]))\n",
    "    val[\"result\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"num_commons_files_used_content_pages\": {\n",
    "#        \"file\": \"queries/num_commons_files.hql\",\n",
    "#        \"engine\": \"spark\"\n",
    "#    },\n",
    "\n",
    "\n",
    "\n",
    "num_commons_files_query = \"\"\" \n",
    "WITH\n",
    "\n",
    "    wiki_content_namespaces as (\n",
    "        select\n",
    "            dbname,\n",
    "            namespace\n",
    "        FROM\n",
    "            wmf_raw.mediawiki_project_namespace_map\n",
    "        WHERE\n",
    "            namespace_is_content = 1\n",
    "            AND snapshot = '{metrics_month}'\n",
    "    )\n",
    "\n",
    "   \n",
    "        SELECT\n",
    "            '{metrics_month_first_day}' AS month,\n",
    "            COUNT(DISTINCT il_to) AS num_commons_files_used_content_pages\n",
    "        FROM\n",
    "            wmf_raw.mediawiki_imagelinks as m\n",
    "            INNER JOIN wiki_content_namespaces AS ns\n",
    "                ON ( ns.namespace = m.il_from_namespace)\n",
    "                AND ns.dbname = m.wiki_db -- recommended by Mikhail to properly run the code\n",
    "        WHERE\n",
    "            m.snapshot = '{metrics_month}'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PySpark executors will use /usr/lib/anaconda-wmf/bin/python3.\n"
     ]
    }
   ],
   "source": [
    "#num_commons_files_used_content_pages = spark.sql(num_commons_files_query.format(**date_params)).toPandas()\n",
    "#merge_in(mce)\n",
    "\n",
    "num_commons_files_df = spark.run(num_commons_files_query.format(**date_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining and saving metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assemble list of result dataframes\n",
    "results = [val[\"result\"] for _, val in queries.items()]\n",
    "\n",
    "# Merge them all, assuming that the month is the only common column\n",
    "new_metrics_subset = reduce(lambda l, r: pd.merge(l, r, how=\"outer\"), results)\n",
    "\n",
    "#add in num_commons_files_used_content_pages\n",
    "new_metrics_prep1 = pd.concat([new_metrics_subset, num_commons_files_df['num_commons_files_used_content_pages']], axis=1)\n",
    "\n",
    "#reorder columns \n",
    "new_metrics_prep = new_metrics_prep1[['month', 'structured_data_used', 'num_commons_files_used_content_pages','wikidata_items']]\n",
    "\n",
    "#Set the month as an index so combine_first works properly\n",
    "new_metrics = new_metrics_prep.set_index(\"month\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_commons_files_used_content_pages</th>\n",
       "      <th>structured_data_used</th>\n",
       "      <th>wikidata_items</th>\n",
       "      <th>wikidata_items_being_reused</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>33853754.0</td>\n",
       "      <td>118873343.0</td>\n",
       "      <td>93808863.0</td>\n",
       "      <td>19464104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>35339547.0</td>\n",
       "      <td>120411293.0</td>\n",
       "      <td>94347261.0</td>\n",
       "      <td>19540328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>35748687.0</td>\n",
       "      <td>121413643.0</td>\n",
       "      <td>94646283.0</td>\n",
       "      <td>19640044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>36017280.0</td>\n",
       "      <td>123036144.0</td>\n",
       "      <td>95086219.0</td>\n",
       "      <td>19801319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>36208503.0</td>\n",
       "      <td>123918750.0</td>\n",
       "      <td>95420570.0</td>\n",
       "      <td>20031718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>36843454.0</td>\n",
       "      <td>124842611.0</td>\n",
       "      <td>95826220.0</td>\n",
       "      <td>20161422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>37096017.0</td>\n",
       "      <td>125887906.0</td>\n",
       "      <td>96153653.0</td>\n",
       "      <td>20266273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>37124441.0</td>\n",
       "      <td>127025510.0</td>\n",
       "      <td>96332960.0</td>\n",
       "      <td>20548393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>37488533.0</td>\n",
       "      <td>127991760.0</td>\n",
       "      <td>96647383.0</td>\n",
       "      <td>20647318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>37898030.0</td>\n",
       "      <td>128971911.0</td>\n",
       "      <td>96908499.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_commons_files_used_content_pages  structured_data_used  \\\n",
       "month                                                                    \n",
       "2021-07-01  33853754.0                            118873343.0            \n",
       "2021-08-01  35339547.0                            120411293.0            \n",
       "2021-09-01  35748687.0                            121413643.0            \n",
       "2021-10-01  36017280.0                            123036144.0            \n",
       "2021-11-01  36208503.0                            123918750.0            \n",
       "2021-12-01  36843454.0                            124842611.0            \n",
       "2022-01-01  37096017.0                            125887906.0            \n",
       "2022-02-01  37124441.0                            127025510.0            \n",
       "2022-03-01  37488533.0                            127991760.0            \n",
       "2022-04-01  37898030.0                            128971911.0            \n",
       "\n",
       "            wikidata_items  wikidata_items_being_reused  \n",
       "month                                                    \n",
       "2021-07-01  93808863.0      19464104.0                   \n",
       "2021-08-01  94347261.0      19540328.0                   \n",
       "2021-09-01  94646283.0      19640044.0                   \n",
       "2021-10-01  95086219.0      19801319.0                   \n",
       "2021-11-01  95420570.0      20031718.0                   \n",
       "2021-12-01  95826220.0      20161422.0                   \n",
       "2022-01-01  96153653.0      20266273.0                   \n",
       "2022-02-01  96332960.0      20548393.0                   \n",
       "2022-03-01  96647383.0      20647318.0                   \n",
       "2022-04-01  96908499.0     NaN                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if old_metrics is None:\n",
    "    metrics = new_metrics\n",
    "else:\n",
    "    metrics = new_metrics.combine_first(old_metrics)\n",
    "    \n",
    "pd_display_all(metrics.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get last value & replace as needed\n",
    "metrics.iloc[-1,c.columns.get_loc(\"wikidata_items_being_reused\")] = #missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(FILENAME, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
